{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3493ec-d8e0-4e94-bbe5-214b88f40d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6addf2-55b6-4aa9-9359-111ea8cee870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83a4d65a-ccb2-41a1-a65e-ea1a15ec5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d877cb45-b024-47fb-8dc4-7b8f81854d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 656 images belonging to 4 classes.\n",
      "Found 38 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(128, 128), batch_size=32, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory('val', target_size=(128, 128), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c96a711-6f7a-4cfe-bd80-2b975a998ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))  # Adjust input_shape\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# Add more convolutional and pooling layers as needed\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daec211a-2627-4c08-bf10-e31085523c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b426968-287c-47a0-a5f8-3029399ea7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad file: training\n",
      "Bad file: .ipynb_checkpoints\n",
      "Bad file: bleached\n",
      "Bad file: unbleached\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def check_images(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(directory, filename))\n",
    "            img.verify()  # Verify the image is not corrupted\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print(f\"Bad file: {filename}\")\n",
    "\n",
    "check_images('train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a89d926-c33f-4597-a0be-e8674255fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7db28f99-6eb3-4635-ab5d-457204ed4063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 28s 1s/step - loss: -1492.2742 - accuracy: 0.2622 - val_loss: 5446.7334 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 23s 1s/step - loss: -14500.7393 - accuracy: 0.2805 - val_loss: 31789.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 24s 1s/step - loss: -60677.3672 - accuracy: 0.2805 - val_loss: 109299.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 19s 866ms/step - loss: -172320.2969 - accuracy: 0.2805 - val_loss: 278098.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 20s 948ms/step - loss: -394388.0000 - accuracy: 0.2805 - val_loss: 585847.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 21s 975ms/step - loss: -764696.0000 - accuracy: 0.2805 - val_loss: 1084920.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 22s 1s/step - loss: -1347185.5000 - accuracy: 0.2805 - val_loss: 1824000.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 20s 919ms/step - loss: -2213935.2500 - accuracy: 0.2805 - val_loss: 2854091.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 22s 1s/step - loss: -3365112.5000 - accuracy: 0.2805 - val_loss: 4249814.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 31s 1s/step - loss: -4916634.0000 - accuracy: 0.2805 - val_loss: 6023660.5000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3ff4c12d3c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=validation_generator, validation_steps=len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f387c22-add8-451b-956f-a32277a6b31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 36ms/step - loss: 6023660.0000 - accuracy: 0.0000e+00\n",
      "Validation accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print('Validation accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349e1ea8-9ee7-455e-a0f1-c83a2b784751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d1aeb-98ff-4dff-85be-4e762e168ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 images belonging to 1 classes.\n",
      "Found 38 images belonging to 1 classes.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up data directories\n",
    "train_dir = 'train/training'\n",
    "validation_dir = 'val'\n",
    "\n",
    "# Create data generators with more aggressive augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=45,\n",
    "                                   width_shift_range=0.25,\n",
    "                                   height_shift_range=0.25,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Define a more complex CNN model with additional layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a different optimizer and learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Run the function on your dataset directories\n",
    "remove_corrupted_images('path_to_train_directory')\n",
    "remove_corrupted_images('path_to_validation_directory')\n",
    "# Train the model with more epochs\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Now, when you run your training, it should load even truncated images\n",
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=20, validation_data=validation_generator, validation_steps=len(validation_generator))\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print('Validation accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b30bb76-01a7-4ce2-8e1d-0e2a57c67b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "new_image = test_datagen.flow_from_directory(\n",
    "    'test', \n",
    "    target_size=(224, 224),  # Use the same dimensions as in the model summary\n",
    "    batch_size=1, \n",
    "    class_mode='binary', \n",
    "    color_mode='rgb'  # If your model uses RGB input\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fdcca417-204a-4197-9084-2648bcdc1a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "for batch in new_image:\n",
    "    print(batch[0].shape)  # Output should be (1, height, width, channels)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e78cd428-6a9b-4b66-83ab-9a3dae4b6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 126ms/step\n",
      "Bleached coral reef\n"
     ]
    }
   ],
   "source": [
    "# Run the prediction\n",
    "prediction = model.predict(new_image)\n",
    "\n",
    "# Since `prediction` is likely an array, access the first element of the array\n",
    "pred_value = prediction[0][0]  # Assuming the prediction is a batch of one image with binary output\n",
    "\n",
    "# Now apply the condition on the scalar value\n",
    "if pred_value > 0.5:\n",
    "    print(\"Healthy coral reef\")\n",
    "else:\n",
    "    print(\"Bleached coral reef\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52c3219c-40e6-4d4d-ae02-a52ba1dfcf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 222, 222, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 111, 111, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 109, 109, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 52, 52, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 26, 26, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 173056)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               88605184  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,976,513\n",
      "Trainable params: 88,976,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c52044-4a2c-42b4-9d09-9530722f7eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
